{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A Steam reviews classifier using Naive Bayes\n\n<div style=\"text-align: justify\">\nSteam is a digital platform for the purchase of video games online. It is run by video game developer Valve.\n\nSteam is one of the main options for purchasing video games online and has millions of active users every month.\n\nOne of the most important features of Steam is its review system. This system helps the user to decide whether to buy a game or not based on the experiences and recommendations of buyers of the game.\n\nThe review system classifies reviews as positive or negative, and cumulative reviews are classified as overhwelmingly positive, very positive, mostly positive, positive, mixed, overhwelmingly negative, very negative, mostly negative and negative.\n\n</div>","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle"}},{"cell_type":"markdown","source":"This notebook presents step by step how to build a review classifier system using the **Na√Øve Bayes algorithm**.","metadata":{}},{"cell_type":"markdown","source":"# Importing the data\nThe data to train the model were obtained from the \"Steam Reviews\" (Sobkowicz A., 2017) dataset available in Kaggle.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsteam_reviews = pd.read_csv('/kaggle/input/steam-reviews/dataset.csv') ","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:07.078831Z","iopub.execute_input":"2023-03-24T00:59:07.079439Z","iopub.status.idle":"2023-03-24T00:59:48.854820Z","shell.execute_reply.started":"2023-03-24T00:59:07.079368Z","shell.execute_reply":"2023-03-24T00:59:48.853493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steam_reviews.head()","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:48.858775Z","iopub.execute_input":"2023-03-24T00:59:48.860031Z","iopub.status.idle":"2023-03-24T00:59:48.875353Z","shell.execute_reply.started":"2023-03-24T00:59:48.859985Z","shell.execute_reply":"2023-03-24T00:59:48.873944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory data analysis","metadata":{}},{"cell_type":"markdown","source":"Once, we have imported the dataset is time to analyze the features and their content starting from the features names.","metadata":{}},{"cell_type":"code","source":"list(steam_reviews.columns)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:48.877260Z","iopub.execute_input":"2023-03-24T00:59:48.878127Z","iopub.status.idle":"2023-03-24T00:59:48.893524Z","shell.execute_reply.started":"2023-03-24T00:59:48.878085Z","shell.execute_reply":"2023-03-24T00:59:48.892023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- app_id: Game ID.\n- app_name: Game name.\n- review_text: Text of the review.\n- review_score: Whether the review recommends the game or not.\n- review_votes: Whether the review was recommended by another user or not.","metadata":{}},{"cell_type":"markdown","source":"Number of dataset rows","metadata":{}},{"cell_type":"code","source":"rows = len(steam_reviews.index)\nrows","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:48.895175Z","iopub.execute_input":"2023-03-24T00:59:48.895677Z","iopub.status.idle":"2023-03-24T00:59:48.908105Z","shell.execute_reply.started":"2023-03-24T00:59:48.895638Z","shell.execute_reply":"2023-03-24T00:59:48.906677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Possible values of column \"review_score\".","metadata":{}},{"cell_type":"code","source":"list(pd.unique(steam_reviews['review_score']))","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:48.911431Z","iopub.execute_input":"2023-03-24T00:59:48.911794Z","iopub.status.idle":"2023-03-24T00:59:48.969884Z","shell.execute_reply.started":"2023-03-24T00:59:48.911760Z","shell.execute_reply":"2023-03-24T00:59:48.968536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see the positive reviews are recorded with a value of 1 and negative reviews are recorded with a value of -1.","metadata":{}},{"cell_type":"markdown","source":"Let's explore the number of games.","metadata":{}},{"cell_type":"code","source":"games = pd.unique(steam_reviews['app_name'])\ngames_count = len(games)\ngames_count","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:48.973584Z","iopub.execute_input":"2023-03-24T00:59:48.974469Z","iopub.status.idle":"2023-03-24T00:59:49.277619Z","shell.execute_reply.started":"2023-03-24T00:59:48.974419Z","shell.execute_reply":"2023-03-24T00:59:49.276613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nnp.random.seed(2810)\nsample_size = 100000\n\nsample_id = np.random.randint(0, rows, sample_size)\n\nsample_data = steam_reviews.loc[sample_id, ['review_text', 'review_score']]","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:49.279290Z","iopub.execute_input":"2023-03-24T00:59:49.279710Z","iopub.status.idle":"2023-03-24T00:59:49.607679Z","shell.execute_reply.started":"2023-03-24T00:59:49.279672Z","shell.execute_reply":"2023-03-24T00:59:49.606254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Positive reviews number vs Negative reviews number","metadata":{}},{"cell_type":"markdown","source":"Let's explore the number of positive and negative reviews in subset.","metadata":{}},{"cell_type":"code","source":"vc = sample_data['review_score'].value_counts().reset_index(name='count')\nvcn = sample_data['review_score'].value_counts(normalize=True).reset_index(name='proportion')\n\nreview_score_stats = pd.merge(vc, vcn, on='index')\nreview_score_stats.rename(columns={'index': 'review_score'}, inplace=True)\nreview_score_stats","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:49.609599Z","iopub.execute_input":"2023-03-24T00:59:49.609961Z","iopub.status.idle":"2023-03-24T00:59:49.635195Z","shell.execute_reply.started":"2023-03-24T00:59:49.609924Z","shell.execute_reply":"2023-03-24T00:59:49.633677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nkind = 'bar'\nbar_color = [\"#09BEC5\", \"#FF7065\"]\n\nfig, axes = plt.subplots(nrows=1,ncols=2)\n\nreview_score_stats.plot(x='review_score', \n                        y='count', \n                        ax = axes[0], \n                        kind=kind, \n                        color=bar_color, \n                        subplots=True,\n                        legend=False)\n\nreview_score_stats.plot(x='review_score', \n                        y='proportion', \n                        ax = axes[1], \n                        kind=kind, \n                        color=bar_color, \n                        subplots=True, \n                        legend=False)\n\nplt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-24T00:59:49.637560Z","iopub.execute_input":"2023-03-24T00:59:49.638001Z","iopub.status.idle":"2023-03-24T00:59:49.891279Z","shell.execute_reply.started":"2023-03-24T00:59:49.637940Z","shell.execute_reply":"2023-03-24T00:59:49.890033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there are many more positive reviews than negative ones.","metadata":{}},{"cell_type":"markdown","source":"### Common reviews","metadata":{}},{"cell_type":"markdown","source":"Let's analyze the information for repeated reviews.","metadata":{}},{"cell_type":"code","source":"# Lowercase review text\nreviews_text = sample_data['review_text'].reset_index(name='text')\n\n# Count occurrences of review text\ntc = reviews_text['text'].value_counts().reset_index(name='count')\ntc.rename(columns={'index': 'text'}, inplace=True)\ntc.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:49.893483Z","iopub.execute_input":"2023-03-24T00:59:49.894758Z","iopub.status.idle":"2023-03-24T00:59:50.142684Z","shell.execute_reply.started":"2023-03-24T00:59:49.894704Z","shell.execute_reply":"2023-03-24T00:59:50.141461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As shown in the table, the text \"early access review\" is repeated too much, this text does not add information to the model, so it will be removed later.","metadata":{}},{"cell_type":"markdown","source":"# Preparing the data","metadata":{}},{"cell_type":"markdown","source":"<div style=\"text-align: justify\">\nBefore creating the model and training it, we must preprocess the text of the reviews. This is in order to reduce the amount of data needed to train the model and improve the accuracy of the model.\n</div>\n\n### Preprocessing steps\n- Lowercase\n- Remove punctuation\n- Remove stop words\n- Stemming\n- Tokenize sentences\n","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.insert(1, \"/kaggle/input/contraction-map\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-03-24T00:59:50.144441Z","iopub.execute_input":"2023-03-24T00:59:50.144784Z","iopub.status.idle":"2023-03-24T00:59:50.150473Z","shell.execute_reply.started":"2023-03-24T00:59:50.144749Z","shell.execute_reply":"2023-03-24T00:59:50.149543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                        u\"\\U00002702-\\U000027B0\"\n                        u\"\\U000024C2-\\U0001F251\"\n                        u\"\\U0001f926-\\U0001f937\"\n                        u\"\\U0001F1F2\"\n                        u\"\\U0001F1F4\"\n                        u\"\\U0001F620\"\n                        u\"\\u200d\"\n                        u\"\\u2640-\\u2642\"\n                        u\"\\u2600-\\u2B55\"\n                        u\"\\u23cf\"\n                        u\"\\u23e9\"\n                        u\"\\u231a\"\n                        u\"\\ufe0f\"  # dingbats\n                        u\"\\u3030\"\n                        u\"\\U00002500-\\U00002BEF\"  # Chinese char\n                        u\"\\U00010000-\\U0010ffff\"\n                        \"]+\", flags=re.UNICODE)\n    \n    return emoji_pattern.sub(r'', text)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:50.152012Z","iopub.execute_input":"2023-03-24T00:59:50.152423Z","iopub.status.idle":"2023-03-24T00:59:50.165283Z","shell.execute_reply.started":"2023-03-24T00:59:50.152366Z","shell.execute_reply":"2023-03-24T00:59:50.164044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from contractions import CONTRACTION_MAP\nimport re\n\n\"\"\"\nOpen source code from Sarkar (2018)\nSarkar, D (2018, August 3rd). \nText Wrangling & Pre-processing: A Practitioner‚Äôs Guide to NLP. KDnuggets. \nRecuperado 6 de marzo de 2023, de https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html\n\"\"\"\n\ndef expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n    \n    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n                                      flags=re.IGNORECASE|re.DOTALL)\n    def expand_match(contraction):\n        match = contraction.group(0)\n        first_char = match[0]\n        expanded_contraction = contraction_mapping.get(match)\\\n                                if contraction_mapping.get(match)\\\n                                else contraction_mapping.get(match.lower())                       \n        expanded_contraction = first_char+expanded_contraction[1:]\n        return expanded_contraction\n        \n    expanded_text = contractions_pattern.sub(expand_match, text)\n    expanded_text = re.sub(\"'\", \"\", expanded_text)\n    return expanded_text","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:50.167472Z","iopub.execute_input":"2023-03-24T00:59:50.167797Z","iopub.status.idle":"2023-03-24T00:59:50.180863Z","shell.execute_reply.started":"2023-03-24T00:59:50.167763Z","shell.execute_reply":"2023-03-24T00:59:50.179787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from unidecode import unidecode\n\nimport string\n\ndef preprocess_review(review):\n    \"\"\"\n    Return a cleaned text (string).\n    \n    Input\n    review: A review text string.\n    -----------------------------------------\n    Output\n    preprocessed_review: A string without digits, \n    emojis and expanded contractions.\n    \"\"\"\n    preproc_review = review.lower() # Lowecase\n    \n    # Replace happy and sad emoticons by \"happy\" and \"sad\" words.\n    SAD_FACE = [':(', ':c']\n    HAPPY_FACE = [':)', ':D']\n    \n    for face in SAD_FACE:\n        if face in preproc_review:\n                preproc_review = preproc_review.replace(face, 'sad')\n                \n    for face in HAPPY_FACE:\n        if face in review:\n                preproc_review = preproc_review.replace(face, 'happy')\n        \n    # Replace ratings by words\n    for match in re.finditer(r'([0-9][0-9]?(\\.[0-9])?|100?)\\/(100?)', preproc_review):\n        numerator =  match.group(1)\n        denominator = match.group(3)\n        rating = float(numerator) / float(denominator)\n        \n        repl_str = f'{numerator}/{denominator}'\n        \n        if rating < 0.5:\n            preproc_review = preproc_review.replace(repl_str, 'terrible')\n        elif rating < 0.6:\n            preproc_review = preproc_review.replace(repl_str, 'bad')\n        elif rating < 0.8:\n            preproc_review = preproc_review.replace(repl_str, 'okay')\n        elif rating < 1:\n            preproc_review = preproc_review.replace(repl_str, 'good')\n        else:\n            preproc_review = preproc_review.replace(repl_str, 'excellent')\n    \n    # Remove digits\n    preproc_review = preproc_review.translate(str.maketrans('', '', '0123456789'))\n    \n    # Remove emojis\n    preproc_review = remove_emoji(preproc_review)\n    \n    # Decode unicode letters to ASCII letters, eg.'ƒ∞,√ñ,√ú,≈û,√á,ƒû' -> 'I,O,U,S,C,G'\n    preproc_review = unidecode(preproc_review)\n    \n    # Expand contractions to avoid losing important information\n    preproc_review = expand_contractions(preproc_review)\n    \n    # Remove punctuation\n    preproc_review = preproc_review.translate(str.maketrans('', '', string.punctuation))\n        \n    return preproc_review","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:50.185526Z","iopub.execute_input":"2023-03-24T00:59:50.186524Z","iopub.status.idle":"2023-03-24T00:59:50.205093Z","shell.execute_reply.started":"2023-03-24T00:59:50.186474Z","shell.execute_reply":"2023-03-24T00:59:50.203838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from nltk.stem import PorterStemmer\nfrom nltk.tokenize import word_tokenize\n\ndef stem_tokenizer(review):\n    \"\"\"\n    Return a collection of stemmed tokens extracted from a review.\n    \n    Input\n    review: A review text string.\n    --------------------------------------------------------------\n    Output\n    A list of strings.\n    \"\"\"\n    # Tokenization\n    review_tokens = word_tokenize(review)\n        \n    ps = PorterStemmer()\n    \n    # Stemming\n    return [ps.stem(word) for word in review_tokens]","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:50.206768Z","iopub.execute_input":"2023-03-24T00:59:50.207169Z","iopub.status.idle":"2023-03-24T00:59:50.223330Z","shell.execute_reply.started":"2023-03-24T00:59:50.207130Z","shell.execute_reply":"2023-03-24T00:59:50.222141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preparing for training","metadata":{}},{"cell_type":"markdown","source":"Once our functions are completed, it is necessary to prepare the data for training the model.","metadata":{}},{"cell_type":"markdown","source":"First, we are going to remove all \"Early Access Review\" entries.","metadata":{}},{"cell_type":"code","source":"data = steam_reviews.copy()\ndata = data.loc[sample_id, ['review_text', 'review_score']]\ndata = data[data['review_text'].str.contains('Early Access Review') == False]","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:50.224834Z","iopub.execute_input":"2023-03-24T00:59:50.225469Z","iopub.status.idle":"2023-03-24T00:59:51.441267Z","shell.execute_reply.started":"2023-03-24T00:59:50.225420Z","shell.execute_reply":"2023-03-24T00:59:51.439917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reviews_text = data['review_text'].reset_index(name='text')\n\n# Count occurrences of review text\ntc = reviews_text['text'].value_counts().reset_index(name='count')\ntc.rename(columns={'index': 'text'}, inplace=True)\ntc.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:51.442889Z","iopub.execute_input":"2023-03-24T00:59:51.443244Z","iopub.status.idle":"2023-03-24T00:59:51.634343Z","shell.execute_reply.started":"2023-03-24T00:59:51.443207Z","shell.execute_reply":"2023-03-24T00:59:51.632836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It can be seen that reviews containing \"Early Access Review\" have been removed.","metadata":{}},{"cell_type":"markdown","source":"#### Splitting dataset","metadata":{}},{"cell_type":"markdown","source":"We will divide the data into training data and test data.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = data.review_text\ny = data.review_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:51.636583Z","iopub.execute_input":"2023-03-24T00:59:51.637131Z","iopub.status.idle":"2023-03-24T00:59:51.680258Z","shell.execute_reply.started":"2023-03-24T00:59:51.637077Z","shell.execute_reply":"2023-03-24T00:59:51.679100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training data will contain 80% of the data and the test data will contain 20% of the data.","metadata":{}},{"cell_type":"markdown","source":"#### Creating feature matrix","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nnew_stopwords = stopwords.words('english')\nnew_stopwords.remove('no')\nnew_stopwords.remove('not')\nnew_stopwords.append('becaus') # \"Because\" misspelled\n\ncustom_stopwords = []\n\nfor w in new_stopwords:\n    custom_stopwords.append(stem_tokenizer(preprocess_review(w))[0])\n\ncustom_vect = CountVectorizer(preprocessor=preprocess_review, \n                             tokenizer=stem_tokenizer,\n                             stop_words=custom_stopwords,\n                             max_features=5000,\n                             binary=True)\n\nX_train_vect = custom_vect.fit_transform(X_train)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T00:59:51.681812Z","iopub.execute_input":"2023-03-24T00:59:51.682250Z","iopub.status.idle":"2023-03-24T01:02:51.026494Z","shell.execute_reply.started":"2023-03-24T00:59:51.682204Z","shell.execute_reply":"2023-03-24T01:02:51.025225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Balancing our training data","metadata":{}},{"cell_type":"markdown","source":"Now we need to sample a balanced subset from our data. Imbalanced data typically refers to a problem with classification problems where the classes are not represented equally, the previous barplot shows us that our sample data is imbalanced.","metadata":{}},{"cell_type":"markdown","source":"To obtain a balanced dataset, we're going to create synthetic negative samples using SMOTE algorithm.","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nfrom imblearn.over_sampling import SMOTE\n\nimbalanced = Counter(y_train)\n\nprint(f'Original dataset shape')\nprint(f'-1: {imbalanced[-1]}, 1: {imbalanced[1]}')\n\nsm = SMOTE(random_state=1142)\nX_train_res, y_train_res = sm.fit_resample(X_train_vect, y_train)\n\nbalanced = Counter(y_train_res)\n\nprint(f'Resampled dataset shape')\nprint(f'-1: {balanced[-1]}, 1: {balanced[1]}')","metadata":{"execution":{"iopub.status.busy":"2023-03-24T01:02:51.028189Z","iopub.execute_input":"2023-03-24T01:02:51.028637Z","iopub.status.idle":"2023-03-24T01:03:00.700523Z","shell.execute_reply.started":"2023-03-24T01:02:51.028589Z","shell.execute_reply":"2023-03-24T01:03:00.699530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, let's create the model using the feature matrix and correct classifications vector.","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\nnb = MultinomialNB()\n\nnb.fit(X_train_res, y_train_res)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-24T01:03:00.701772Z","iopub.execute_input":"2023-03-24T01:03:00.703001Z","iopub.status.idle":"2023-03-24T01:03:00.750988Z","shell.execute_reply.started":"2023-03-24T01:03:00.702958Z","shell.execute_reply":"2023-03-24T01:03:00.749693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb.score(X_train_res, y_train_res)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T01:03:00.752581Z","iopub.execute_input":"2023-03-24T01:03:00.753197Z","iopub.status.idle":"2023-03-24T01:03:00.792934Z","shell.execute_reply.started":"2023-03-24T01:03:00.753153Z","shell.execute_reply":"2023-03-24T01:03:00.791454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Once, the model s created, it is time to test it.\nFor testing, it is necessary create another feature matrix with our testing data.","metadata":{}},{"cell_type":"code","source":"X_test_vect = custom_vect.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-03-24T01:03:00.794449Z","iopub.execute_input":"2023-03-24T01:03:00.794804Z","iopub.status.idle":"2023-03-24T01:03:45.058880Z","shell.execute_reply.started":"2023-03-24T01:03:00.794744Z","shell.execute_reply":"2023-03-24T01:03:45.057478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then, we're going to use our model to predict the classification for each row un our feature matrix.","metadata":{}},{"cell_type":"code","source":"y_pred = nb.predict(X_test_vect)\n\ny_pred","metadata":{"execution":{"iopub.status.busy":"2023-03-24T01:03:45.060659Z","iopub.execute_input":"2023-03-24T01:03:45.061118Z","iopub.status.idle":"2023-03-24T01:03:45.075354Z","shell.execute_reply.started":"2023-03-24T01:03:45.061069Z","shell.execute_reply":"2023-03-24T01:03:45.074104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we will compare model classification predictions against real classifications.","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n\nprint(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\nprint(\"\\nF1 Score: {:.2f}\".format(f1_score(y_test, y_pred) * 100))\nprint(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-03-24T01:11:36.204863Z","iopub.execute_input":"2023-03-24T01:11:36.206575Z","iopub.status.idle":"2023-03-24T01:11:36.236641Z","shell.execute_reply.started":"2023-03-24T01:11:36.206507Z","shell.execute_reply":"2023-03-24T01:11:36.235042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## References\nAntoni Sobkowicz. (2017). Steam Review Dataset (2017) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.1000885\n\nSarkar, D (2018, August 3rd). \nText Wrangling & Pre-processing: A Practitioner‚Äôs Guide to NLP. KDnuggets. \nRetrieved March 6th 2023, from https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html","metadata":{}}]}